{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics and Mining\n",
    "\n",
    "- Unstructured text data is being generated all the time\n",
    "\n",
    "- Text analytics / Text mining involves techniques and algorithms for analyzing text\n",
    "\n",
    "- Traditional data mining techniques may be used if text is converted to numerical vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Techniques\n",
    "- NLTK: stemming, stopwords, punctuation, top words\n",
    "- WordCloud: visualization\n",
    "- TF-IDF Vectorizer with sklearn\n",
    "- Topic Modeling with gensim\n",
    "- Sentiment analysis with TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer with sklearn\n",
    "- Vectorizers are used to transform words into numbers\n",
    "\n",
    "- Some use a CountVectorizer â€“ just raw counts of each word in each document\n",
    "\n",
    "- But it is recommended to use TfidfVectorizer, which weights words by importance, not just by frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) CountVectorizer (i.e. Term Frequency)\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Mock Data For Demonstration Purposes\n",
    "doc1 = \"the moving finger writes and having writ moves on\"\n",
    "doc2 = \"the gold finger or golden finger the question is moot\"\n",
    "doc3 = \"he is a finger spinner and can write with it too\"\n",
    "doc4 = \"the valiant never taste of death but once or so they say\"\n",
    "doc5 = \"knights are valiant and never afraid of death\"\n",
    "corpus = [doc1, doc2, doc3, doc4, doc5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **fit_transform( )** method \"tokenize the strings and give you a vector for each string\". \n",
    "> \n",
    "> The vector is the total number of tokens for the whole corpus.\n",
    "> \n",
    "> Each dimension of which corresponds to the number of times a token is found in the corresponding string. \n",
    "> \n",
    "> So, it has both (1) determined which tokens it will count, and (2) how they correspond to entries in the count vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(5, 18)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words = 'english')            # Create an instance object of CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(corpus) # Tokenize all the strings in the corpus and return a vector for each string\n",
    "# csr_matrix: Compressed Sparse Matrix\n",
    "print(type(matrix))\n",
    "# The Number of Documents and the Total Number of Tokens\n",
    "print(matrix.shape)                       # Print a stucture of the outcome (i.e. matrix variable) of fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **vocabulary_** method \"returns a dictionary that represents pairs of a token and its corresponding vector\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'moving': 9, 'finger': 2, 'writes': 17, 'having': 5, 'writ': 15, 'moves': 8, 'gold': 3, 'golden': 4, 'question': 10, 'moot': 7, 'spinner': 12, 'write': 16, 'valiant': 14, 'taste': 13, 'death': 1, 'say': 11, 'knights': 6, 'afraid': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 2)\t2\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 7)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 16)\t1\n",
      "  (3, 14)\t1\n",
      "  (3, 13)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 11)\t1\n",
      "  (4, 14)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 6)\t1\n",
      "  (4, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **get_feature_names( )** method \"returns a list that represents all the tokens (i.e. word) appearing in the corpus\". Each token is a feature of the instance object of CountVectorizer( )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afraid', 'death', 'finger', 'gold', 'golden', 'having', 'knights', 'moot', 'moves', 'moving', 'question', 'say', 'spinner', 'taste', 'valiant', 'writ', 'write', 'writes']\n"
     ]
    }
   ],
   "source": [
    "# Let's Investigate Features of the Instance Object\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **toarray ( )** method \"return a dense ndarray representation of the given matrix\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each Document Is Represented as a Term-Frequency Vector, Where Each Dimension Corresponds to a Word\n",
    "matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1]\n",
      " [0 0 2 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0]\n",
      " [1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(matrix.toarray())\n",
    "# But, It Is Not Clear Which Feature Name (i.e. Token or Word) Is Corresponding to the Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afraid:0 death:0 finger:1 gold:0 golden:0 having:1 knights:0 moot:0 moves:1 moving:1 question:0 say:0 spinner:0 taste:0 valiant:0 writ:1 write:0 writes:1 \n",
      "\n",
      "afraid:0 death:0 finger:2 gold:1 golden:1 having:0 knights:0 moot:1 moves:0 moving:0 question:1 say:0 spinner:0 taste:0 valiant:0 writ:0 write:0 writes:0 \n",
      "\n",
      "afraid:0 death:0 finger:1 gold:0 golden:0 having:0 knights:0 moot:0 moves:0 moving:0 question:0 say:0 spinner:1 taste:0 valiant:0 writ:0 write:1 writes:0 \n",
      "\n",
      "afraid:0 death:1 finger:0 gold:0 golden:0 having:0 knights:0 moot:0 moves:0 moving:0 question:0 say:1 spinner:0 taste:1 valiant:1 writ:0 write:0 writes:0 \n",
      "\n",
      "afraid:1 death:1 finger:0 gold:0 golden:0 having:0 knights:1 moot:0 moves:0 moving:0 question:0 say:0 spinner:0 taste:0 valiant:1 writ:0 write:0 writes:0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's Combine the Feature Names and the Frequency. Note That They Are List Objects and Share the Same Index.\n",
    "for doc in matrix.toarray():\n",
    "    for idx in range(len(doc)):\n",
    "        print('{}:{}'.format(vectorizer.get_feature_names()[idx], doc[idx]), end = ' ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***As we saw before, there are several words (i.e. fingers, etc.) that frequently appear in the text.***\n",
    "> ***But those words do not have the \"distinguishing\" power.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Solution: TF-IDF Vectorizer\n",
    "\n",
    "- TF: Term Frequency: how many times a word appear in a document?\n",
    "\n",
    "- IDF: Inverse Document Frequency: how many documents include the word?\n",
    "\n",
    "- TF-IDF(t, d, D) = TF(t, d) * IDF(t, D)\n",
    "\n",
    "- IDF(t, D) = log( N / |{d in D:  t in d}| )\n",
    "- N: total number of documents in the corpus\n",
    "\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afraid', 'death', 'finger', 'gold', 'golden', 'having', 'knights', 'moot', 'moves', 'moving', 'question', 'say', 'spinner', 'taste', 'valiant', 'writ', 'write', 'writes']\n",
      "(5, 18)\n",
      "[[0.         0.         0.28691208 0.         0.         0.42841136\n",
      "  0.         0.         0.42841136 0.42841136 0.         0.\n",
      "  0.         0.         0.         0.42841136 0.         0.42841136]\n",
      " [0.         0.         0.55645052 0.41544037 0.41544037 0.\n",
      "  0.         0.41544037 0.         0.         0.41544037 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.42799292 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.63907044 0.         0.         0.         0.63907044 0.        ]\n",
      " [0.         0.44400208 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.55032913\n",
      "  0.         0.55032913 0.44400208 0.         0.         0.        ]\n",
      " [0.55032913 0.44400208 0.         0.         0.         0.\n",
      "  0.55032913 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.44400208 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Mock Data For Demonstration Purposes\n",
    "doc1 = \"the moving finger writes and having writ moves on\"\n",
    "doc2 = \"the gold finger or golden finger the question is moot\"\n",
    "doc3 = \"he is a finger spinner and can write with it too\"\n",
    "doc4 = \"the valiant never taste of death but once or so they say\"\n",
    "doc5 = \"knights are valiant and never afraid of death\"\n",
    "docs = [doc1, doc2, doc3, doc4, doc5]\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(stop_words = 'english') # The only difference is the type of vectorizer\n",
    "matrix2 = vectorizer2.fit_transform(docs)\n",
    "print(vectorizer2.get_feature_names())\n",
    "print(matrix2.shape)\n",
    "print(matrix2.toarray()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Compare (1) CounterVectorizer and (2) TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afraid', 'death', 'finger', 'gold', 'golden', 'having', 'knights', 'moot', 'moves', 'moving', 'question', 'say', 'spinner', 'taste', 'valiant', 'writ', 'write', 'writes']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()) # (1)CounterVectorizer\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afraid', 'death', 'finger', 'gold', 'golden', 'having', 'knights', 'moot', 'moves', 'moving', 'question', 'say', 'spinner', 'taste', 'valiant', 'writ', 'write', 'writes']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vectorizer2.get_feature_names()) # (2)TFIDFVectorizer\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1]\n",
      " [0 0 2 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0]\n",
      " [1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(matrix.toarray()) # (1)CounterVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.28691208 0.         0.         0.42841136\n",
      "  0.         0.         0.42841136 0.42841136 0.         0.\n",
      "  0.         0.         0.         0.42841136 0.         0.42841136]\n",
      " [0.         0.         0.55645052 0.41544037 0.41544037 0.\n",
      "  0.         0.41544037 0.         0.         0.41544037 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.42799292 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.63907044 0.         0.         0.         0.63907044 0.        ]\n",
      " [0.         0.44400208 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.55032913\n",
      "  0.         0.55032913 0.44400208 0.         0.         0.        ]\n",
      " [0.55032913 0.44400208 0.         0.         0.         0.\n",
      "  0.55032913 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.44400208 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(matrix2.toarray()) # (2)TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Practice:  Let's Calculate the Pairwise Document Distance with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Mock Data For Demonstration Purposes\n",
    "doc1 = \"the moving finger writes and having writ moves on\"\n",
    "doc2 = \"gold finger or golden finger the question is moot\"\n",
    "doc3 = \"he is a finger spinner and can write with it too\"\n",
    "doc4 = \"the valiant never taste of death but once or so they say\"\n",
    "doc5 = \"knights are valiant and never afraid of death\"\n",
    "docs = [doc1, doc2, doc3, doc4, doc5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['afraid', 'death', 'finger', 'gold', 'golden', 'having', 'knights', 'moot', 'moves', 'moving', 'question', 'say', 'spinner', 'taste', 'valiant', 'writ', 'write', 'writes']\n",
      "(5, 18)\n",
      "[[0.         0.         0.28691208 0.         0.         0.42841136\n",
      "  0.         0.         0.42841136 0.42841136 0.         0.\n",
      "  0.         0.         0.         0.42841136 0.         0.42841136]\n",
      " [0.         0.         0.55645052 0.41544037 0.41544037 0.\n",
      "  0.         0.41544037 0.         0.         0.41544037 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.42799292 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.63907044 0.         0.         0.         0.63907044 0.        ]\n",
      " [0.         0.44400208 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.55032913\n",
      "  0.         0.55032913 0.44400208 0.         0.         0.        ]\n",
      " [0.55032913 0.44400208 0.         0.         0.         0.\n",
      "  0.55032913 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.44400208 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "matrix = vectorizer.fit_transform(docs)\n",
    "print(len(docs))\n",
    "print(vectorizer.get_feature_names())\n",
    "print(matrix.shape)\n",
    "print(matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **cosine_distances( )** method \"takes an object, computes cosine distance between samples in the object, and returns a distance matrix\".\n",
    ">\n",
    "> Cosine distance is defined as 1.0 minus the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "cos_dist = cosine_distances(matrix)\n",
    "print(cos_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.84034762 0.87720366 1.         1.        ]\n",
      " [0.84034762 0.         0.76184312 1.         1.        ]\n",
      " [0.87720366 0.76184312 0.         1.         1.        ]\n",
      " [1.         1.         1.         0.         0.60572431]\n",
      " [1.         1.         1.         0.60572431 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(cos_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: The Pairwise Document Cosine-Distance with TF (i.e. CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.71132487 0.76429774 1.         1.        ]\n",
      " [0.71132487 0.         0.59175171 1.         1.        ]\n",
      " [0.76429774 0.59175171 0.         1.         1.        ]\n",
      " [1.         1.         1.         0.         0.5       ]\n",
      " [1.         1.         1.         0.5        0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "doc1 = \"the moving finger writes and having writ moves on\"\n",
    "doc2 = \"gold finger or golden finger the question is moot\"\n",
    "doc3 = \"he is a finger spinner and can write with it too\"\n",
    "doc4 = \"the valiant never taste of death but once or so they say\"\n",
    "doc5 = \"knights are valiant and never afraid of death\"\n",
    "docs = [doc1, doc2, doc3, doc4, doc5]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "matrix = vectorizer.fit_transform(docs)\n",
    "cos_dist = cosine_distances(matrix)\n",
    "print(cos_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice: The Pairwise Document Cosine-Distance with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.88543955 0.65820921]\n",
      " [0.88543955 0.         0.91959811]\n",
      " [0.65820921 0.91959811 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "doc1 = open('frankenstein.txt').read()\n",
    "doc2 = open('raven.txt').read()\n",
    "doc3 = open('abbey.txt').read()\n",
    "docs = [doc1, doc2, doc3]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "matrix = vectorizer.fit_transform(docs)\n",
    "cos_dist = cosine_distances(matrix)\n",
    "print(cos_dist)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
